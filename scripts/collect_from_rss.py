# c:\MyProjects\SingularityDaily\scripts\collect_from_rss.py
import os
import feedparser
import logging
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from .common_utils import (
    strip_html_tags,
    fetch_article_body,
    safe_filename,
    get_existing_english_titles_from_dir, # ìƒˆë¡œìš´ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    translate_text,
    summarize_and_translate_body,
    initialize_gemini,
)
from . import config

# --- Constants ---
MIN_BODY_LENGTH = 300
MAX_ENTRIES_PER_FEED = 10  # ì¼ë°˜ í”¼ë“œëŠ” í•­ëª©ì´ ë§ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œí•œ
OUTPUT_DIR = config.ARTICLES_PATH  # ì„¤ì • íŒŒì¼ì—ì„œ 'articles' ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°

# --- Logging Setup ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

def save_markdown(title_ko, title_en, summary_ko, url):
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì €ì¥í•˜ê³ , ì¤‘ë³µì„ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        safe_title = safe_filename(title_ko)
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        path = os.path.join(OUTPUT_DIR, f"{safe_title}.md")

        with open(path, "w", encoding="utf-8") as f:
            f.write(f"# {title_ko}\n\n")
            f.write(f"**ì›ì œëª©:** {title_en}\n\n")
            f.write(f"**ìš”ì•½:** {summary_ko}\n\n")
            f.write(f"[ì›ë¬¸ ë§í¬]({url})\n")
        logging.info(f"âœ… ì €ì¥ ì™„ë£Œ: {path}")
        return True
    except Exception as e:
        logging.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({title_en}): {e}", exc_info=True)
        return False

def process_entry(entry, existing_titles, lock):
    """ê°œë³„ RSS í•­ëª©ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    try:
        title_en = strip_html_tags(entry.get("title", ""))
        link = entry.get("link", "")

        if not title_en or not link:
            logging.warning("ì œëª© ë˜ëŠ” ë§í¬ê°€ ì—†ëŠ” í•­ëª©ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False

        with lock:
            if title_en in existing_titles:
                logging.info(f"ğŸš« ì¤‘ë³µ ê¸°ì‚¬: {title_en}")
                return False
            existing_titles.add(title_en)

        body = fetch_article_body(link)

        if not body or len(body.strip()) < MIN_BODY_LENGTH:
            logging.info(f"âš ï¸ ë³¸ë¬¸ ë¶€ì¡±/ì¶”ì¶œ ì‹¤íŒ¨ â€” ì €ì¥í•˜ì§€ ì•ŠìŒ: {title_en}")
            return False

        title_ko = translate_text(title_en)
        summary_ko = summarize_and_translate_body(body)
        
        if not title_ko or not summary_ko:
            logging.error(f"ë²ˆì—­ ì‹¤íŒ¨: {title_en}")
            return False

        if save_markdown(title_ko, title_en, summary_ko, link):
            return True # ì œëª©ì€ ì´ë¯¸ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.
        return False

    except Exception as e:
        logging.error(f"í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({entry.get('title', 'N/A')}): {e}", exc_info=True)
        return False

def main():
    """ëª¨ë“  ì¼ë°˜ RSS í”¼ë“œë¥¼ ìˆœíšŒí•˜ë©° ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        initialize_gemini()
    except (ValueError, RuntimeError) as e:
        logging.error(f"ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ë‹¨: {e}")
        exit(1)

    # ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘ ì‹œ, ê¸°ì¡´ì— ì €ì¥ëœ ëª¨ë“  ê¸°ì‚¬ì˜ ì›ì œëª©ì„ ë¯¸ë¦¬ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
    existing_titles = get_existing_english_titles_from_dir(OUTPUT_DIR)
    logging.info(f"ê¸°ì¡´ 'ê¸°ì‚¬' {len(existing_titles)}ê°œì˜ ì›ì œëª©ì„ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    lock = threading.Lock()

    all_tasks = []
    for feed_url in config.RSS_FEEDS:
        logging.info(f"========== ğŸŒ ì¼ë°˜ RSS í”¼ë“œ ìŠ¤ìº” ì¤‘: {feed_url} ==========")
        try:
            feed = feedparser.parse(feed_url)
            if feed.bozo:
                logging.warning(f"í”¼ë“œ íŒŒì‹± ë¬¸ì œ ({feed_url}): {feed.bozo_exception}")

            entries = feed.entries[:MAX_ENTRIES_PER_FEED]
            all_tasks.extend(entries)
        except Exception as e:
            logging.error(f"í”¼ë“œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({feed_url}): {e}")

    if not all_tasks:
        logging.info("ì²˜ë¦¬í•  ìƒˆ ì¼ë°˜ RSS í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    logging.info(f"ì´ {len(all_tasks)}ê°œì˜ ì¼ë°˜ RSS í•­ëª©ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤...")

    successful_saves = 0
    with ThreadPoolExecutor(max_workers=3) as executor:
        future_to_task = {executor.submit(process_entry, task, existing_titles, lock): task for task in all_tasks}
        
        for i, future in enumerate(as_completed(future_to_task), 1):
            logging.info(f"  - ì¼ë°˜ ê¸°ì‚¬ ì§„í–‰ë¥ : {i}/{len(all_tasks)} ì²˜ë¦¬ ì™„ë£Œ...")
            try:
                if future.result() is True:
                    successful_saves += 1
            except Exception as exc:
                task = future_to_task[future]
                logging.error(f"í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ ({task.get('title', 'N/A')}): {exc}")

    logging.info(f"========== ì¼ë°˜ RSS ìˆ˜ì§‘ ì¢…ë£Œ: ì´ {successful_saves}ê°œì˜ ìƒˆ ê¸°ì‚¬ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤. ==========\n")

if __name__ == "__main__":
    main()