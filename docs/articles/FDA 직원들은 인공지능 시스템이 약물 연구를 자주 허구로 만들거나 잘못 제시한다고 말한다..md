# FDA 직원들은 인공지능 시스템이 약물 연구를 자주 허구로 만들거나 잘못 제시한다고 말한다.

**원제목:** FDA is using an AI system that staff say frequently invents or misrepresents drug research

**요약:** 미국 식품의약국(FDA)은 신약 평가에 생성형 AI 시스템인 엘사(Elsa)를 활용하고 있지만, 내부 정보에 따르면 엘사는 정기적으로 연구 자료를 허구로 만들어낸다는 문제점을 가지고 있습니다.  엘사는 신약 승인 절차를 가속화하기 위해 고안되었으나, FDA 직원들은 엘사가 자주 연구 결과를 날조하거나 잘못 해석한다고 지적하며,  이는 대규모 언어 모델의 잘 알려진 한계점이라고 설명합니다.  특히, 검증 시간 부족으로 인해 신뢰성이 떨어진다는 우려가 제기되고 있습니다. FDA의 AI 책임자인 제레미 월시는 이러한 문제를 인정하며, 엘사가 다른 많은 생성형 AI와 마찬가지로 허구적인 정보를 생성할 가능성이 있다고 밝혔습니다.  현재 미국 의료 분야에는 AI에 대한 구속력 있는 규정이 없어 엘사의 사용은 규제의 회색 지대에 놓여 있습니다.  하지만 엘사는 이미 임상 프로토콜 검토 및 검사 중 위험 평가에 사용되고 있으며,  이러한 상황은 AI의 신뢰성과 안전성에 대한 심각한 우려를 불러일으킵니다.  따라서 FDA는 엘사의 활용에 대한  엄격한 검증 및 규제 방안 마련이 시급한 상황입니다.  결론적으로, 엘사의 효율성과 신뢰성 사이의 균형을 맞추는 것이 중요한 과제로 남아 있습니다.

[원문 링크](https://the-decoder.com/fda-is-using-an-ai-system-that-staff-say-frequently-invents-or-misrepresents-drug-research/)
