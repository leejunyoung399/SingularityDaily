# FDA 직원들은 인공지능 시스템이 약물 연구를 자주 날조하거나 잘못 제시한다고 말한다.

**원제목:** FDA is using an AI system that staff say frequently invents or misrepresents drug research

**요약:** 미국 식품의약국(FDA)은 신약 평가를 위해 Elsa라는 생성형 AI 시스템을 활용하고 있으나, 내부 고발에 따르면 Elsa는 연구 결과를 허위로 만들어내는 경우가 빈번하다고 합니다.  Elsa는 신약 승인 절차를 가속화하기 위해 고안되었지만, 직원들은 Elsa가 자주 연구 자료를 날조하거나 잘못 해석한다고 증언하며, 이는 대규모 언어 모델의 일반적인 문제점이라고 지적했습니다.  FDA의 AI 책임자인 Jeremy Walsh 또한 Elsa를 포함한 생성형 AI의 환각 현상 가능성을 인정했습니다.  현재 미국 의료 분야에는 AI에 대한 구속력 있는 규정이 없어 Elsa의 운용은 규제의 회색 지대에 놓여 있습니다.  Elsa는 이미 임상 프로토콜 검토 및 검사 중 위험 평가에 사용되고 있으며,  이는 신뢰할 수 없는 정보에 의존하는 위험을 내포하고 있습니다.  철저한 검증 없이 사용되는 AI 시스템의 한계가 드러나고 있으며,  FDA는 이러한 위험을 인지하고 있음에도 불구하고  Elsa 활용을 지속하고 있습니다. 따라서  AI 기반 의료 시스템의 신뢰성 확보 및 규제 강화에 대한 논의가 시급합니다.  결론적으로,  Elsa의 활용은 신속성과 정확성 사이에서 균형을 찾아야 하는 어려운 과제를 제시합니다.

[원문 링크](https://the-decoder.com/fda-is-using-an-ai-system-that-staff-say-frequently-invents-or-misrepresents-drug-research/)
