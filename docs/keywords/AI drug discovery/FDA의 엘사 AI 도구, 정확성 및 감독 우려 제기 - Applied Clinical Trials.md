# FDA의 엘사 AI 도구, 정확성 및 감독 우려 제기 - Applied Clinical Trials

**원제목:** FDA's Elsa AI Tool Raises Accuracy and Oversight Concerns - Applied Clinical Trials

**요약:** 미국 식품의약국(FDA)의 내부 AI 어시스턴트인 ‘엘사’가 허위 인용 및 데이터 착각(hallucination)과 같은 정확성 문제를 겪고 있다는 연구 결과가 발표되었다.  엘사는 프로토콜 검토 및 라벨 비교와 같은 작업을 신속하게 처리하기 위해 개발되었으나, 현재의 한계로 인해 공식적인 규제 평가에는 사용될 수 없다.  특히 AI 출력물에 대한 감독 및 검증 체계가 불분명하여 의약품 개발 과정의 신뢰성에 대한 우려가 제기된다.  CNN의 보도에 따르면, 엘사는 존재하지 않는 연구를 인용하는 등의 오류를 지속적으로 발생시키고 있으며, FDA 내부 직원들 또한 이러한 문제점을 확인하였다.  엘사는 대규모 언어 모델 기반으로, 요약, 코드 생성 등의 기능을 제공하지만, 정확성 검증 없이 사용될 경우 신뢰할 수 없다는 지적이 나온다. FDA 국장은 엘사의 오류 가능성을 인정하며,  향후 개선 및 직원들의 활용 능력 향상을 약속하였다.  하지만 FDA의 인력 감축 및 인사 이동으로 업무 지연이 발생하고 있으며, 이는 엘사의 도입에도 불구하고,  효율성 개선에 대한 의문을 제기한다.  결론적으로,  엘사는 잠재력을 가지고 있지만,  정확성 확보 및 신뢰할 수 있는 검증 체계 구축 없이는  FDA의 효율적인 운영에 기여하기 어려울 것으로 예상된다.  따라서,  AI 모델의 신뢰성 확보를 위한  지속적인 연구와  개선이 필수적이다.

[원문 링크](https://www.appliedclinicaltrialsonline.com/view/fda-elsa-ai-tool-raises-accuracy-and-oversight-concerns)
