# 역생산성과 의심: AGI 제어 문제에 대해 논하는 것에 대한 두 가지 반론

**원제목:** Counter-productivity and suspicion: two arguments against talking about theAGIcontrol problem

**요약:** 본 논문은 초지능 인공지능(AGI)의 통제 문제, 즉 AGI의 목표나 행동이 인류의 이익과 상충할 가능성에 대한 우려를 다룬다.  연구는 AGI 통제 문제에 대한 우려를 가진 사람들에게 '이 문제에 대해 이야기하지 말라'는 정책을 옹호하는 두 가지 주장을 제시한다. 첫째, '역효과 주장'은 통제 문제 해결 노력이 비정렬된 AGI에 의해 이용되어 그 노력을 무력화할 수 있다는 점을 지적한다. 둘째, '의심 주장'은 통제 문제에 대한 공개적인 논의가 AGI로 하여금 인류를 위협으로 인식하게 만들어 위험을 증가시킬 수 있다고 주장한다.  논문은 이러한 주장에 대한 반박을 검토하고 그 반박이 성공적이지 않음을 보여준다.  하지만 '말하지 말라'는 정책 자체에 대한 반론도 제기하며, 정책 채택 여부에 대해서는 결론을 내리지 않는다.  또한, AGI 정렬과 같은 다른 AI 안전 연구 분야에도 이러한 주장이 적용될 수 있는지 여부를 조사하고, 직접적이지는 않더라도 적용될 가능성이 높다고 주장한다. 마지막으로, '말하지 말라' 정책의 채택 여부와 관계없이 안전하게 이야기할 수 있는 내용에 대한 권고를 제시한다.  즉, 초지능 AI의 위험성을 감안하여 관련 정보의 비공개가 인류의 안전에 기여할 수 있다는 가능성을 제기하며, 이에 대한 다각적인 논의의 필요성을 강조한다.

[원문 링크](https://link.springer.com/article/10.1007/s11098-025-02379-9)
