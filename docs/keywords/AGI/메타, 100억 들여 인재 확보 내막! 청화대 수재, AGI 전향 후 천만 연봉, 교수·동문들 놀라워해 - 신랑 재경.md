# 메타, 100억 들여 인재 확보 내막! 청화대 수재, AGI 전향 후 천만 연봉, 교수·동문들 놀라워해 - 신랑 재경

**원제목:** Meta百亿抢人内幕！清华学霸转行AGI拿千万年薪，教授校友看呆了 - 新浪财经

**요약:** 본 연구는 Meta에서 개발한 다양한 크기의 언어 모델(LLM)인 Phi 시리즈(Phi-2, Phi-3, Phi-4)와 이를 훈련하는 데 사용된 방법론, 그리고 이를 통해 도출된 결론을 상세히 다루고 있습니다.  연구진은 LoRA(Low-Rank Adaptation)를 활용하여 비교적 적은 계산 자원으로 효율적인 LLM 훈련을 수행하였습니다.  특히,  'Physics of Language Models'라는 새로운 프레임워크를 제시하여 언어 모델의 물리적 특성을 이해하고 개선하는 데 초점을 맞췄습니다.  2014년부터 시작된 연구는 2018년의 연구 결과를 토대로 발전을 거듭하여,  Meta의 AGI 개발 목표 달성에 기여할 것으로 기대됩니다.  연구 결과, Phi 시리즈는 기존 모델들에 비해 우수한 성능을 보였으며,  다양한 크기의 모델들이 각기 다른 작업에서 최적의 성능을 발휘하는 것을 확인했습니다.  또한,  Meta는  Scale AI, Turing AI, Toloka와 같은 여러 기업들과 협력하여 데이터 라벨링 및 모델 평가를 진행하였고,  이를 통해  데이터 라벨링의 중요성과  효율적인 데이터 활용 전략의 필요성을 강조하였습니다.  마지막으로,  본 연구는  대규모 언어 모델 개발에 있어서  자원 효율성과  성능 향상을 동시에 달성할 수 있는 가능성을 제시하며,  향후  AI 개발 방향에 중요한 시사점을 제공합니다.  특히,  OpenAI의 Gemini 2.5와 비교 분석을 통해 Meta의 LLM의 경쟁력을 보여주고 있습니다.

[원문 링크](https://finance.sina.com.cn/tech/csj/2025-07-26/doc-infhvmwn1767254.shtml)
